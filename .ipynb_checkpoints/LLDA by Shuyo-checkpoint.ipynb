{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Labeled Latent Dirichlet Allocation\n",
    "# This code is available under the MIT License.\n",
    "# (c)2010 Nakatani Shuyo / Cybozu Labs Inc.\n",
    "# refer to Ramage+, Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora(EMNLP2009)\n",
    "\n",
    "from optparse import OptionParser\n",
    "import sys, re, numpy\n",
    "import pdb\n",
    "\n",
    "def load_corpus(filename):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    labelmap = dict()\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        mt = re.match(r'\\[(.+?)\\](.+)', line)\n",
    "        if mt:\n",
    "            label = mt.group(1).split(',')\n",
    "            for x in label: labelmap[x] = 1\n",
    "            line = mt.group(2)\n",
    "        else:\n",
    "            label = None\n",
    "        doc = re.findall(r'\\w+(?:\\'\\w+)?',line.lower())\n",
    "        if len(doc)>0:\n",
    "            corpus.append(doc)\n",
    "            labels.append(label)\n",
    "    f.close()\n",
    "    return labelmap.keys(), corpus, labels\n",
    "\n",
    "class LLDA:\n",
    "    \"\"\"Labeled LDA class\n",
    "    \n",
    "    Attributes:\n",
    "        alpha: Dirichlet parameter prior to per-document-topic distribution.\n",
    "        beta: Dirichlet parameter prior to per-topic word distribution.\n",
    "        K: Number of unique labels in corpus.\n",
    "        V: Vocabulary (list of all words)\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, K, alpha, beta):\n",
    "        #self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def term_to_id(self, term):\n",
    "        if term not in self.vocas_id:\n",
    "            voca_id = len(self.vocas)\n",
    "            self.vocas_id[term] = voca_id\n",
    "            self.vocas.append(term)\n",
    "        else:\n",
    "            voca_id = self.vocas_id[term]\n",
    "        return voca_id\n",
    "\n",
    "    def complement_label(self, label):\n",
    "        if not label: return numpy.ones(len(self.labelmap))\n",
    "        vec = numpy.zeros(len(self.labelmap))\n",
    "        vec[0] = 1.0\n",
    "        for x in label: vec[self.labelmap[x]] = 1.0\n",
    "        return vec\n",
    "\n",
    "    def set_corpus(self, labelset, corpus, labels):\n",
    "        \"\"\"Setting corpus for this LLDA object.\n",
    "        \n",
    "        Args:\n",
    "            labelset(list): List of labels.\n",
    "            corpus\n",
    "        \"\"\"\n",
    "        labelset.insert(0, \"common\")\n",
    "        # Sets mapping of labels to their indexes.\n",
    "        self.labelmap = dict(zip(labelset, range(len(labelset))))\n",
    "        self.K = len(self.labelmap)\n",
    "\n",
    "        self.vocas = []\n",
    "        self.vocas_id = dict()\n",
    "        self.labels = numpy.array([self.complement_label(label) for label in labels])\n",
    "        self.docs = [[self.term_to_id(term) for term in doc] for doc in corpus]\n",
    "\n",
    "        M = len(corpus)\n",
    "        V = len(self.vocas)\n",
    "\n",
    "        self.z_m_n = []\n",
    "        self.n_m_z = numpy.zeros((M, self.K), dtype=int)\n",
    "        self.n_z_t = numpy.zeros((self.K, V), dtype=int)\n",
    "        self.n_z = numpy.zeros(self.K, dtype=int)\n",
    "\n",
    "        for m, doc, label in zip(range(M), self.docs, self.labels):\n",
    "            N_m = len(doc)\n",
    "            #z_n = [label[x] for x in numpy.random.randint(len(label), size=N_m)]\n",
    "            z_n = [numpy.random.multinomial(1, label / label.sum()).argmax() for x in range(N_m)]\n",
    "            pdb.set_trace()\n",
    "            self.z_m_n.append(z_n)\n",
    "            for t, z in zip(doc, z_n):\n",
    "                self.n_m_z[m, z] += 1\n",
    "                self.n_z_t[z, t] += 1\n",
    "                self.n_z[z] += 1\n",
    "\n",
    "    def inference(self):\n",
    "        V = len(self.vocas)\n",
    "        for m, doc, label in zip(range(len(self.docs)), self.docs, self.labels):\n",
    "            for n in range(len(doc)):\n",
    "                t = doc[n]\n",
    "                z = self.z_m_n[m][n]\n",
    "                self.n_m_z[m, z] -= 1\n",
    "                self.n_z_t[z, t] -= 1\n",
    "                self.n_z[z] -= 1\n",
    "\n",
    "                denom_a = self.n_m_z[m].sum() + self.K * self.alpha\n",
    "                denom_b = self.n_z_t.sum(axis=1) + V * self.beta\n",
    "                p_z = label * (self.n_z_t[:, t] + self.beta) / denom_b * (self.n_m_z[m] + self.alpha) / denom_a\n",
    "                new_z = numpy.random.multinomial(1, p_z / p_z.sum()).argmax()\n",
    "\n",
    "                self.z_m_n[m][n] = new_z\n",
    "                self.n_m_z[m, new_z] += 1\n",
    "                self.n_z_t[new_z, t] += 1\n",
    "                self.n_z[new_z] += 1\n",
    "\n",
    "    def phi(self):\n",
    "        V = len(self.vocas)\n",
    "        return (self.n_z_t + self.beta) / (self.n_z[:, numpy.newaxis] + V * self.beta)\n",
    "\n",
    "    def theta(self):\n",
    "        \"\"\"document-topic distribution\"\"\"\n",
    "        n_alpha = self.n_m_z + self.labels * self.alpha\n",
    "        return n_alpha / n_alpha.sum(axis=1)[:, numpy.newaxis]\n",
    "\n",
    "    def perplexity(self, docs=None):\n",
    "        if docs == None: docs = self.docs\n",
    "        phi = self.phi()\n",
    "        thetas = self.theta()\n",
    "\n",
    "        log_per = N = 0\n",
    "        for doc, theta in zip(docs, thetas):\n",
    "            for w in doc:\n",
    "                log_per -= numpy.log(numpy.inner(phi[:,w], theta))\n",
    "            N += len(doc)\n",
    "        return numpy.exp(log_per / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age of building', 'link', 'features', 'measurement unit', 'address']\n",
      "[['1191', 'route', '785', 'utopia', 'new', 'brunswick', 'new', 'brunswick', 'e5c2l3', '0533759'], ['http', 'www', 'realtor', 'ca', 'propertydetails', 'aspx', 'propertyid', '15119807'], ['4', 'years'], ['imperial'], ['modern', 'luxurious', 'architectural'], ['finest', 'property', 'in', 'new', 'brunswick', 'modern', 'luxurious', 'architectural', 'home', 'takes', 'full', 'advantage', 'of', 'center', 'stage', 'on', 'lake', 'utopia', 'in', 'st', 'george', 'panoramic', 'views', 'of', 'the', 'lake', '27', '000', 'sq', 'ft', 'under', 'roof', 'and', '100', 'acres', 'of', 'unspoiled', 'natural', 'beauty', 'experience', 'resort', 'style', 'living', 'with', '3', 'homes', '2', 'tournament', 'quality', 'outdoor', 'tennis', 'courts', 'and', '1', 'stadium', 'quality', 'indoor', 'tennis', 'court', 'with', 'state', 'of', 'the', 'art', 'indoor', 'stadium', 'lighting', 'water', 'park', 'including', '2', 'pools', 'wading', 'pool', 'with', 'umbrella', 'feature', 'beach', 'volleyball', 'court', 'baseball', 'field', 'custom', 'go', 'kart', 'track', 'driving', 'range', 'indoor', 'basketball', 'court', 'playground', 'private', 'dock', 'with', 'boat', 'lift', 'and', '3', 'private', 'beaches', 'main', 'home', 'offers', 'expanses', 'of', 'glass', 'flooding', 'the', 'interior', 'with', 'brilliant', 'light', 'sleek', 'contemporary', 'design', 'dramatic', 'master', 'suite', 'with', 'custom', 'shower', 'central', 'tub', 'showcasing', 'unparalleled', 'views', 'master', 'lanai', 'with', 'drapery', 'screening', 'and', 'built', 'in', 'jacuzzi', 'two', 'guest', 'homes', 'provide', 'luxurious', 'privacy', 'for', 'visitors', 'enjoying', 'this', 'exquisite', 'estate', 'welcome', 'to', 'paradise'], ['1191', 'route', '785', 'utopia', 'new', 'brunswick', 'new', 'brunswick', 'e5c2l3', '0533759']]\n",
      "[['address'], ['link'], ['age of building'], ['measurement unit'], ['features'], None, None]\n",
      "> <ipython-input-47-61892734abb0>(64)complement_label()\n",
      "-> return vec\n",
      "(Pdb) label\n",
      "['address']\n",
      "(Pdb) vec\n",
      "array([ 1.,  0.,  0.,  0.,  0.,  1.])\n",
      "(Pdb) self.labelmap\n",
      "{'features': 3, 'measurement unit': 4, 'age of building': 1, 'link': 2, 'common': 0, 'address': 5}\n",
      "(Pdb) len(labelset)\n",
      "6\n",
      "(Pdb) range(len(labelset))\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "(Pdb) labelset\n",
      "['common', 'age of building', 'link', 'features', 'measurement unit', 'address']\n"
     ]
    }
   ],
   "source": [
    "parser = OptionParser()\n",
    "parser.add_option(\"-f\", dest=\"filename\", help=\"corpus filename\")\n",
    "parser.add_option(\"--alpha\", dest=\"alpha\", type=\"float\", help=\"parameter alpha\", default=0.001)\n",
    "parser.add_option(\"--beta\", dest=\"beta\", type=\"float\", help=\"parameter beta\", default=0.001)\n",
    "parser.add_option(\"-k\", dest=\"K\", type=\"int\", help=\"number of topics\", default=20)\n",
    "parser.add_option(\"-i\", dest=\"iteration\", type=\"int\", help=\"iteration count\", default=100)\n",
    "(options, args) = parser.parse_args()\n",
    "if not options.filename: parser.error(\"need corpus filename(-f)\")\n",
    "\n",
    "labeled_file_path = 'pdfs/labeled/05337591.pdf.txt'\n",
    "labelset, corpus, labels = load_corpus(labeled_file_path)\n",
    "print(labelset)\n",
    "print(corpus)\n",
    "print(labels)\n",
    "\n",
    "llda = LLDA(options.K, options.alpha, options.beta)\n",
    "llda.set_corpus(labelset, corpus, labels)\n",
    "\n",
    "for i in range(options.iteration):\n",
    "    sys.stderr.write(\"-- %d \" % (i + 1))\n",
    "    llda.inference()\n",
    "#print llda.z_m_n\n",
    "\n",
    "phi = llda.phi()\n",
    "for v, voca in enumerate(llda.vocas):\n",
    "    print ','.join([voca]+[str(x) for x in llda.n_z_t[:,v]])\n",
    "#     print ','.join([voca]+[str(x) for x in phi[:,v]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Labeled LDA using nltk.corpus.reuters as dataset\n",
    "# This code is available under the MIT License.\n",
    "# (c)2013 Nakatani Shuyo / Cybozu Labs Inc.\n",
    "\n",
    "import sys, string, random, numpy\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "parser = OptionParser()\n",
    "parser.add_option(\"--alpha\", dest=\"alpha\", type=\"float\", help=\"parameter alpha\", default=0.001)\n",
    "parser.add_option(\"--beta\", dest=\"beta\", type=\"float\", help=\"parameter beta\", default=0.001)\n",
    "parser.add_option(\"-k\", dest=\"K\", type=\"int\", help=\"number of topics\", default=50)\n",
    "parser.add_option(\"-i\", dest=\"iteration\", type=\"int\", help=\"iteration count\", default=100)\n",
    "parser.add_option(\"-s\", dest=\"seed\", type=\"int\", help=\"random seed\", default=None)\n",
    "parser.add_option(\"-n\", dest=\"samplesize\", type=\"int\", help=\"dataset sample size\", default=100)\n",
    "(options, args) = parser.parse_args()\n",
    "random.seed(options.seed)\n",
    "numpy.random.seed(options.seed)\n",
    "\n",
    "idlist = random.sample(reuters.fileids(), options.samplesize)\n",
    "\n",
    "labels = []\n",
    "corpus = []\n",
    "for id in idlist:\n",
    "    labels.append(reuters.categories(id))\n",
    "    corpus.append([x.lower() for x in reuters.words(id) if x[0] in string.ascii_letters])\n",
    "    reuters.words(id).close()\n",
    "labelset = list(set(reduce(list.__add__, labels)))\n",
    "\n",
    "\n",
    "llda = LLDA(options.K, options.alpha, options.beta)\n",
    "llda.set_corpus(labelset, corpus, labels)\n",
    "\n",
    "print \"M=%d, V=%d, L=%d, K=%d\" % (len(corpus), len(llda.vocas), len(labelset), options.K)\n",
    "\n",
    "for i in range(options.iteration):\n",
    "    sys.stderr.write(\"-- %d : %.4f\\n\" % (i, llda.perplexity()))\n",
    "    llda.inference()\n",
    "print \"perplexity : %.4f\" % llda.perplexity()\n",
    "\n",
    "phi = llda.phi()\n",
    "for k, label in enumerate(labelset):\n",
    "    print \"\\n-- label %d : %s\" % (k, label)\n",
    "    for w in numpy.argsort(-phi[k])[:20]:\n",
    "        print \"%s: %.4f\" % (llda.vocas[w], phi[k,w])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
